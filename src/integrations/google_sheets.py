import requests
import re
from datetime import datetime, timedelta
from typing import Optional, Union, Any, List, Dict
from src.config import GOOGLE_API_KEY, GOOGLE_SHEET_ID, logger
from src.utils import retry_with_backoff, google_sheets_rate_limiter
from src.utils.security import InputValidator, ValidationResult


def gdrive_to_direct(url: str) -> str:
    """Konwertuje URL Google Drive na bezpośredni link do pobierania"""
    match = re.search(r'/d/([a-zA-Z0-9_-]+)', url)
    if match:
        file_id = match.group(1)
        return f"https://drive.google.com/uc?export=download&id={file_id}"
    return url


def validate_and_sanitize_sheet_data(raw_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Waliduje i sanityzuje dane z arkusza Google Sheets"""
    validated_data = []
    invalid_rows_count = 0
    
    for row_idx, row in enumerate(raw_data, start=2):  # Start from 2 because row 1 is headers
        try:
            # Sanityzuj wszystkie wartości tekstowe
            sanitized_row = {}
            for key, value in row.items():
                if isinstance(value, str):
                    # Usuń potencjalnie niebezpieczne znaki
                    sanitized_value = re.sub(r'[<>"\';\\]', '', value.strip())
                    # Ogranicz długość
                    if len(sanitized_value) > 5000:
                        sanitized_value = sanitized_value[:5000]
                        logger.warning(f"Skrócono zbyt długą wartość w wierszu {row_idx}, kolumna '{key}'")
                    sanitized_row[key] = sanitized_value
                else:
                    sanitized_row[key] = value
            
            # Sprawdź czy wiersz zawiera wymagane dane
            has_content = any(str(value).strip() for value in sanitized_row.values() if value)
            
            if has_content:
                validated_data.append(sanitized_row)
            else:
                logger.debug(f"Pominięto pusty wiersz {row_idx}")
                
        except Exception as e:
            invalid_rows_count += 1
            logger.warning(f"Błąd podczas walidacji wiersza {row_idx}: {e}")
            continue
    
    if invalid_rows_count > 0:
        logger.warning(f"Pominięto {invalid_rows_count} nieprawidłowych wierszy podczas walidacji")
    
    logger.info(f"Zwalidowano {len(validated_data)} wierszy z {len(raw_data)} oryginalnych")
    return validated_data


def parsuj_date_value(date_value: Union[str, int, float, None]) -> Optional[datetime]:
    """Parsuje wartość daty z Google Sheets (może być string lub liczba)"""
    if not date_value:
        return None

    # Jeśli to liczba (serial date number z Google Sheets/Excel)
    if isinstance(date_value, (int, float)):
        try:
            # Google Sheets używa serial date number (liczba dni od 30.12.1899)
            excel_epoch = datetime(1899, 12, 30)
            data_publikacji = excel_epoch + timedelta(days=int(date_value))
            return data_publikacji.date()
        except Exception as e:
            logger.warning(f"Nie można sparsować serial date number {date_value}: {e}")
            return None

    # Jeśli to string, spróbuj różnych formatów
    data_str = str(date_value).strip()
    if not data_str:
        return None

    possible_formats = [
        "%d.%m.%Y",  # 08.08.2025
        "%d/%m/%Y",  # 08/08/2025
        "%Y-%m-%d",  # 2025-08-08
        "%Y-%m-%d %H:%M:%S",  # 2025-08-08 10:00:00
        "%d-%m-%Y",  # 08-08-2025
        "%m/%d/%Y",  # 08/08/2025 (US format)
        "%Y.%m.%d",  # 2025.08.08
    ]

    for date_format in possible_formats:
        try:
            if ' ' in data_str and '%H:%M:%S' in date_format:
                return datetime.strptime(data_str, date_format).date()
            elif ' ' not in data_str and '%H:%M:%S' not in date_format:
                return datetime.strptime(data_str, date_format).date()
        except ValueError:
            continue

    return None


@retry_with_backoff(
    max_retries=3,
    base_delay=2.0,
    exceptions=(requests.RequestException, requests.HTTPError)
)
def pobierz_zdjecia_z_arkusza(sheet_id: str) -> Dict[str, str]:
    """Pobiera wszystkie zdjęcia z arkusza Google Sheets z retry mechanism"""
    try:
        google_sheets_rate_limiter.wait_if_needed()
        
        # Pobierz metadane arkusza zawierające informacje o obrazkach
        url = f"https://sheets.googleapis.com/v4/spreadsheets/{sheet_id}"
        params = {
            'key': GOOGLE_API_KEY,
            'includeGridData': 'true'
        }

        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()

        data = response.json()
        images_by_position = {}

        # Przeszukaj arkusz w poszukiwaniu obrazków
        if 'sheets' in data and len(data['sheets']) > 0:
            sheet_data = data['sheets'][0]
            if 'data' in sheet_data and len(sheet_data['data']) > 0:
                grid_data = sheet_data['data'][0]
                if 'rowData' in grid_data:
                    for row_idx, row in enumerate(grid_data['rowData']):
                        if 'values' in row:
                            for col_idx, cell in enumerate(row['values']):
                                # Sprawdź czy komórka zawiera obrazek
                                if 'formattedValue' in cell and cell['formattedValue'].startswith('=IMAGE'):
                                    # Wyciągnij URL z formuły =IMAGE("url")
                                    formula = cell['formattedValue']
                                    start = formula.find('"') + 1
                                    end = formula.rfind('"')
                                    if start > 0 and end > start:
                                        image_url = formula[start:end]
                                        images_by_position[f"{row_idx},{col_idx}"] = image_url
                                        logger.info(f"Znaleziono obrazek na pozycji ({row_idx},{col_idx}): {image_url}")

        return images_by_position

    except Exception as e:
        logger.error(f"Błąd podczas pobierania obrazków z arkusza: {e}")
        return {}


def znajdz_zdjecie_dla_wiersza(sheet_id: str, row_index: int) -> Optional[str]:
    """Znajduje zdjęcie dla konkretnego wiersza"""
    try:
        # Pobierz wszystkie obrazki z arkusza
        images = pobierz_zdjecia_z_arkusza(sheet_id)

        # Szukaj obrazka w wierszu (row_index+1 bo liczymy od 0, ale arkusz od 1)
        for position, url in images.items():
            pos_row, pos_col = map(int, position.split(','))
            if pos_row == row_index + 1:  # +1 bo pierwszy wiersz to nagłówki
                from image_utils import pobierz_i_zapisz_zdjecie
                return pobierz_i_zapisz_zdjecie(url, row_index)

        # Jeśli nie znaleziono obrazka w konkretnym wierszu, sprawdź kolumnę "sciezka_zdjecia" (indeks 3)
        target_position = f"{row_index + 1},3"  # Wiersz, kolumna D (sciezka_zdjecia)
        if target_position in images:
            from image_utils import pobierz_i_zapisz_zdjecie
            return pobierz_i_zapisz_zdjecie(images[target_position], row_index)

        return None

    except Exception as e:
        logger.error(f"Błąd podczas wyszukiwania zdjęcia dla wiersza {row_index}: {e}")
        return None


@retry_with_backoff(
    max_retries=3,
    base_delay=2.0,
    exceptions=(requests.RequestException, requests.HTTPError)
)
def wczytaj_arkusz(sheet_id: str) -> List[Dict[str, Any]]:
    """Wczytuje dane z arkusza Google Sheets z retry mechanism"""
    try:
        google_sheets_rate_limiter.wait_if_needed()
        
        url = f"https://sheets.googleapis.com/v4/spreadsheets/{sheet_id}/values/A:Z"
        params = {
            'key': GOOGLE_API_KEY,
            'valueRenderOption': 'FORMATTED_VALUE'  # Zmieniono na FORMATTED_VALUE dla lepszego parsowania dat
        }

        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()

        data = response.json()
        values = data.get('values', [])

        if not values:
            logger.warning("Arkusz jest pusty")
            return []

        # Pierwszy wiersz to nagłówki
        headers = values[0]
        dane = []

        logger.info(f"Nagłówki arkusza: {headers}")

        # Przetwórz pozostałe wiersze
        raw_data = []
        for row_idx, row in enumerate(values[1:], start=1):
            row_dict = {}
            for i, header in enumerate(headers):
                if i < len(row):
                    row_dict[header] = row[i]
                else:
                    row_dict[header] = ''
            raw_data.append(row_dict)
            logger.debug(f"Wiersz {row_idx + 1}: {row_dict}")

        logger.info(f"Wczytano {len(raw_data)} surowych wierszy z arkusza")
        
        # Waliduj i sanityzuj dane
        validated_data = validate_and_sanitize_sheet_data(raw_data)
        
        logger.info(f"Zwrócono {len(validated_data)} zwalidowanych wierszy z arkusza")
        return validated_data

    except requests.exceptions.RequestException as e:
        logger.error(f"Błąd HTTP podczas wczytywania arkusza: {e}")
        raise
    except Exception as e:
        logger.error(f"Błąd podczas wczytywania arkusza: {e}")
        raise


def test_parsowania_dat() -> None:
    """Testuje parsowanie dat z arkusza"""
    try:
        dane = wczytaj_arkusz(GOOGLE_SHEET_ID)
        print(f"\n📊 Znaleziono {len(dane)} wierszy w arkuszu")

        if dane:
            print("\n📋 Dostępne kolumny w arkuszu:")
            for header in dane[0].keys():
                print(f"  - '{header}'")

            print("\n📄 Dane pierwszego wiersza:")
            for key, value in dane[0].items():
                print(f"  {key}: '{value}' (typ: {type(value).__name__})")

        print("\n🔍 Sprawdzanie formatów dat:")

        for i, row in enumerate(dane):
            date_value = row.get('data_publikacji', '')
            print(f"\nWiersz {i + 2}: '{date_value}' (typ: {type(date_value).__name__})")

            if not date_value:
                print("  ❌ Brak daty")
                continue

            # Użyj nowej funkcji parsowania
            data_publikacji = parsuj_date_value(date_value)

            if data_publikacji:
                print(f"  ✅ Sparsowano: {data_publikacji}")

                # Sprawdź czy to dzisiaj
                dzisiejsza_data = datetime.now().date()
                if data_publikacji == dzisiejsza_data:
                    print(f"  🎯 TO DZISIAJ! ({dzisiejsza_data})")
                else:
                    dni_do_publikacji = (data_publikacji - dzisiejsza_data).days
                    if dni_do_publikacji > 0:
                        print(f"  📅 Za {dni_do_publikacji} dni")
                    else:
                        print(f"  📅 {abs(dni_do_publikacji)} dni temu")
            else:
                print(f"  ❌ Nie można sparsować")

        print(f"\n📅 Dzisiejsza data: {datetime.now().date()}")

    except Exception as e:
        print(f"❌ Błąd podczas testu: {e}")